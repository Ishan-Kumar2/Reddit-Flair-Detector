{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=pd.read_csv('../dataset/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train['Title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data\n",
    "del train_data['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>idx</th>\n",
       "      <th>Title</th>\n",
       "      <th>Score</th>\n",
       "      <th>ID</th>\n",
       "      <th>Image</th>\n",
       "      <th>Num_Comments</th>\n",
       "      <th>Created</th>\n",
       "      <th>Body</th>\n",
       "      <th>Label1Coronovirus</th>\n",
       "      <th>Label2Politics</th>\n",
       "      <th>Label3Non-Political</th>\n",
       "      <th>Label4Objects</th>\n",
       "      <th>Label5AskIndia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Coronavirus (COVID-19) Megathread - News and U...</td>\n",
       "      <td>287</td>\n",
       "      <td>fqqdsg</td>\n",
       "      <td>https://www.reddit.com/r/india/comments/fqqdsg...</td>\n",
       "      <td>6834</td>\n",
       "      <td>1.585451e+09</td>\n",
       "      <td>**Central thread for sharing coronavirus News ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Firozabad police fact-checking zee news (trans...</td>\n",
       "      <td>680</td>\n",
       "      <td>fwcz7h</td>\n",
       "      <td>https://i.redd.it/jbal4gxocbr41.jpg</td>\n",
       "      <td>62</td>\n",
       "      <td>1.586258e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Donald Trump talks of ‘retaliation’ if India t...</td>\n",
       "      <td>371</td>\n",
       "      <td>fwclvi</td>\n",
       "      <td>https://economictimes.indiatimes.com/industry/...</td>\n",
       "      <td>135</td>\n",
       "      <td>1.586257e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Mom came up with this impressive idea to celeb...</td>\n",
       "      <td>3129</td>\n",
       "      <td>fvz69t</td>\n",
       "      <td>https://i.redd.it/gurfdfd1e7r41.jpg</td>\n",
       "      <td>183</td>\n",
       "      <td>1.586210e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>9 PM 9 Minutes: House Catches Fire In Bihar; G...</td>\n",
       "      <td>181</td>\n",
       "      <td>fwdysc</td>\n",
       "      <td>https://news.abplive.com/news/india/coronaviru...</td>\n",
       "      <td>14</td>\n",
       "      <td>1.586262e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  idx                                              Title  Score  \\\n",
       "0           0    0  Coronavirus (COVID-19) Megathread - News and U...    287   \n",
       "1           1    1  Firozabad police fact-checking zee news (trans...    680   \n",
       "2           2    2  Donald Trump talks of ‘retaliation’ if India t...    371   \n",
       "3           3    3  Mom came up with this impressive idea to celeb...   3129   \n",
       "4           4    4  9 PM 9 Minutes: House Catches Fire In Bihar; G...    181   \n",
       "\n",
       "       ID                                              Image  Num_Comments  \\\n",
       "0  fqqdsg  https://www.reddit.com/r/india/comments/fqqdsg...          6834   \n",
       "1  fwcz7h                https://i.redd.it/jbal4gxocbr41.jpg            62   \n",
       "2  fwclvi  https://economictimes.indiatimes.com/industry/...           135   \n",
       "3  fvz69t                https://i.redd.it/gurfdfd1e7r41.jpg           183   \n",
       "4  fwdysc  https://news.abplive.com/news/india/coronaviru...            14   \n",
       "\n",
       "        Created                                               Body  \\\n",
       "0  1.585451e+09  **Central thread for sharing coronavirus News ...   \n",
       "1  1.586258e+09                                                  0   \n",
       "2  1.586257e+09                                                  0   \n",
       "3  1.586210e+09                                                  0   \n",
       "4  1.586262e+09                                                  0   \n",
       "\n",
       "   Label1Coronovirus  Label2Politics  Label3Non-Political  Label4Objects  \\\n",
       "0                  1               0                    0              0   \n",
       "1                  0               1                    0              0   \n",
       "2                  1               0                    0              0   \n",
       "3                  0               0                    1              0   \n",
       "4                  0               0                    1              0   \n",
       "\n",
       "   Label5AskIndia  \n",
       "0               0  \n",
       "1               0  \n",
       "2               0  \n",
       "3               0  \n",
       "4               0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_sents=[]\n",
    "for i in range(train_data.shape[0]):\n",
    "    title_sents.append(train_data.loc[i,'Title'])\n",
    "    \n",
    "        \n",
    "#title_sents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Framework and Packages used\n",
    "I chose to use torchtext and spacy for the preprocessing of text as I am working on PyTorch and these packages provide most of the utilities needed.\n",
    "\n",
    "## Torchtext\n",
    "If it is not already installed uncomment line 1 For official documentation -https://torchtext.readthedocs.io/en/latest/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "#pip install torchtext\n",
    "import torchtext\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Applied\n",
    "\n",
    "## The Text has to preprocessed and broken into indiviual tokens from sentences before they can be embedded or sent to a model\n",
    "### 1. Tokenisation\n",
    "    -Done using spacy tokeniser. Better to use this rather than normal .split() method\n",
    "    as it seperates punctuation attached to words like the what is (what?) and (what)\n",
    "    would have been treated differently in .split method, but not with spacy\n",
    "### 2. Lemmatisation\n",
    "    -Also using Spacy, basically converts some word which are derived from otherwords to their root word. Like sleeping is converted to sleep.\n",
    "### 3. Punctuation Removal\n",
    "    -String class of python provides a list of all punctuations. Insteead of removing all punctuations, I decided to keep '?' as I think it does add some value in deciding the flair \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "k=string.punctuation\n",
    "punct=[]\n",
    "for i in range(len(k)):\n",
    "    if(k[i]=='?'):\n",
    "        continue\n",
    "    else: \n",
    "        punct.append(k[i])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "spacy_eng=spacy.load('en')\n",
    "nlp=spacy.load(\"en_core_web_sm\")\n",
    "stop=set(stopwords.words('english'))\n",
    "def tokenize_eng(text):\n",
    "    sent=[]\n",
    "    lema=nlp(text)\n",
    "    for tok in spacy_eng.tokenizer(text):\n",
    "        \n",
    "        word=tok.lemma_\n",
    "        #word=tok.text\n",
    "        \n",
    "        if word not in punct:\n",
    "            if word not in stop:\n",
    "                if(word!=word.split('_')[0]):\n",
    "                    sent.extend(word.split('_'))\n",
    "                else:\n",
    "                    sent.append(word)\n",
    "    \n",
    "    return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenised ['Donald', 'Trump', 'talk', '‘', 'retaliation', '’', 'India', 'turn', 'Covid', 'drug', 'request']\n",
      "Original  ['Donald Trump talks of ‘retaliation’ if India turns down Covid drug request']\n"
     ]
    }
   ],
   "source": [
    "sent=train_data.loc[2,'Title']\n",
    "sent_=tokenize_eng(sent)\n",
    "print(f\"Tokenised {sent_}\")\n",
    "print(f\"Original  {[sent]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Torchtext Fields\n",
    "Torchtext can be used to load the data with certain preprocessing done while loading. The way this can be done is by declaring a Field. The Field specifies how you want a certain field to be processed.\n",
    "\n",
    "I Have defined 3 fields for different types of data in my training set\n",
    "\n",
    "### 1. TEXT-\n",
    "For the textual data Title and body of the post\n",
    "\n",
    "### 2. LABEL-\n",
    "For the Output class Labels(Flairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data import Field\n",
    "\n",
    "\n",
    "TEXT=Field(sequential=True,tokenize=tokenize_eng,lower=True,batch_first=True)\n",
    "LABEL=Field(sequential=False,use_vocab=False,batch_first=True)\n",
    "#NUM=Field(sequential=True,use_vocab=False,tokenize=toke,batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torchtext.data import TabularDataset\n",
    "\n",
    "flair_fields=[('Unnamed:0',None),\n",
    "        ('Unnamed: 0.1',None),\n",
    "        ('idx',None),\n",
    "         ('Title',TEXT),\n",
    "         ('Score',None),\n",
    "         ('ID',None),\n",
    "         ('Image',None),\n",
    "         ('Num_Comments',None),\n",
    "         ('Created',None),\n",
    "         ('Body',None),\n",
    "         ('Label1Coronovirus',LABEL),\n",
    "         ('Label2Politics',LABEL),\n",
    "         ('Label3Non-Political',LABEL),\n",
    "         ('Label4Objects',LABEL),\n",
    "         ('Label5AskIndia',LABEL)]\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_csv=TabularDataset(path='../dataset/train.csv',\n",
    "                    format='csv',\n",
    "                    skip_header=True,\n",
    "                    fields=flair_fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title- ['donald', 'trump', 'talk', '‘', 'retaliation', '’', 'india', 'turn', 'covid', 'drug', 'request']\n",
      "Label for Coronavirus- 1\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Example of Datapoint \"\"\"\n",
    "print(f\"Title- {train_data_csv[2].Title}\")\n",
    "print(f\"Label for Coronavirus- {train_data_csv[2].Label1Coronovirus}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vocab Building\n",
    "The TEXT Field requires a vocab using which it can numericalise the words Now either this vocab can be made using the given dataset or can be downloaded from a pretrained word embedding within the build_vocab feature of the Field\n",
    "\n",
    "Here I have used Fasttext 300d Word Embedding and GloVe 200d."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT.build_vocab(train_data_csv,min_freq=1,vectors='fasttext.simple.300d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2160"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(TEXT.vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting to Batches\n",
    "I decided to use Mini Batch gradient descent over Batch or SGD as Batch may take alot of time in RNN and SGD may be unstable\n",
    "\n",
    "## Iterator Used\n",
    "I used BucketIterator from torchtext which has the feature to club similar sized variable together so as to minimize padding required. Here this grouping I did using Context length as that varies largely between examples ranging from 0 to 14000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `device` argument should be set by using `torch.device` or passing a string as an argument. This behavior will be deprecated soon and currently defaults to cpu.\n"
     ]
    }
   ],
   "source": [
    "from torchtext.data import Iterator,BucketIterator\n",
    "\n",
    "train_iterator=BucketIterator(train_data_csv,\n",
    "                             batch_size=32,\n",
    "                             device=-1,\n",
    "                             sort_key=lambda x:len(x.Title),\n",
    "                             sort_within_batch=False,\n",
    "                             repeat=False\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Title', 'Label1Coronovirus', 'Label2Politics', 'Label3Non-Political', 'Label4Objects', 'Label5AskIndia'])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_csv[1].__dict__.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([300])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Each word's representation should be 300 dim\n",
    "TEXT.vocab.vectors[100].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([300])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT.vocab.vectors[100].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Label1Coronovirus',\n",
       " 'Label2Politics',\n",
       " 'Label3Non-Political',\n",
       " 'Label4Objects',\n",
       " 'Label5AskIndia']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=list(train_data_csv[0].__dict__.keys())\n",
    "labels=a[1:]\n",
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making a Wrapper Function for the batches¶\n",
    "Currently the Iterator returns a function of torchtext.Batch type. Using this directly we'll need to define attributes in the train loop which will become messy and non resuable. Instead this wrapper function does that for each batch and returns a tuple of the type\n",
    "\n",
    "(X[title], X[body], (X[num_comments], X[score]), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class BatchWrapper:\n",
    "    def __init__(self,dat,x_var,*y_vars):\n",
    "        self.dat=dat\n",
    "        self.x_vars=x_var\n",
    "        self.y_vars=y_vars\n",
    "        \n",
    "    def __iter__(self):\n",
    "        for batch in self.dat:\n",
    "            x=getattr(batch,self.x_vars)\n",
    "            y=torch.cat([getattr(batch,y).unsqueeze(1) for y in self.y_vars[0]],dim=1).float()\n",
    "            \n",
    "            yield(x,y)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dat)\n",
    "        \n",
    "train_dat=BatchWrapper(train_iterator,'Title',labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "torch.Size([32, 5])\n",
      "torch.Size([32, 33])\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Example of the Wrapped Iterator\"\"\"\n",
    "for x,y in enumerate(train_dat):\n",
    "    print(x)\n",
    "    print(y[1].shape)\n",
    "    \n",
    "    print(y[0].shape)\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Gives one training example'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Gives one training example\"\"\"\n",
    "#next(train_dat.__iter__())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretrained vectors of Embedding\n",
    "The weights of embedding will be copied to nn.Embedding layer. These weights are usually frozen during backprop, but I decided to not do that since many words like covid dont exist in vocab and currently have a 0 embbedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_vecs=TEXT.vocab.vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "\n",
    "## Title Model\n",
    "In this model I have used a BiLSTM for the Title. The reason I went for bidirectional LSTM is because it gets context from both sides of the word. This allows better representation of the word. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self,n_vocab,\n",
    "                 pretrained_vec,\n",
    "                batch_size=16,\n",
    "                embedding_dim=50,\n",
    "                hidden_dim=64,\n",
    "                num_layer=2,\n",
    "                 dropout=0.3,\n",
    "                 output_dims=5,\n",
    "                bidirectional=True):\n",
    "        super(Model,self).__init__()\n",
    "        self.n_vocab=n_vocab\n",
    "        self.batch_size=batch_size\n",
    "        self.embedding_dim=embedding_dim\n",
    "        self.hidden_dim=hidden_dim\n",
    "        self.num_layer=num_layer\n",
    "        self.bidirectional=bidirectional\n",
    "        self.dropout=dropout\n",
    "        \n",
    "        self.output_dims=output_dims\n",
    "        \n",
    "        self.embedding=nn.Embedding(n_vocab,embedding_dim)\n",
    "        self.embedding.weight.data.copy_(pretrained_vec)\n",
    "        self.embedding.weight.requires_grad=False\n",
    "        \n",
    "        \n",
    "        self.rnn=nn.LSTM(self.embedding_dim, self.hidden_dim,\n",
    "                       num_layers=self.num_layer,\n",
    "                       batch_first=True,bidirectional=self.bidirectional,\n",
    "                        dropout=0.5)\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.fc1=nn.Linear(hidden_dim*2,self.output_dims)\n",
    "        \n",
    "        self.dropout=nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self,data):\n",
    "           \n",
    "        embedded=self.embedding(data)\n",
    "        output,(hidden,_)=self.rnn(embedded)\n",
    "        \n",
    "        hidden=self.dropout(torch.cat((hidden[-1,:,:],hidden[-2,:,:]),dim=1))\n",
    "        \n",
    "        output=F.softmax(self.fc1(hidden))\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(\n",
      "  (embedding): Embedding(2160, 300)\n",
      "  (rnn): LSTM(300, 256, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)\n",
      "  (fc1): Linear(in_features=512, out_features=5, bias=True)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "ENC_EMB_DIM=300\n",
    "HID_DIM=256\n",
    "ENC_DROPOUT=0.5\n",
    "\n",
    "Input_Vocab=len(TEXT.vocab)\n",
    "\n",
    "model=Model(n_vocab=Input_Vocab,pretrained_vec=pretrained_vecs,embedding_dim=ENC_EMB_DIM,hidden_dim=HID_DIM,\n",
    "           dropout=ENC_DROPOUT)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import torch.optim as optim\n",
    "optimizer=optim.Adam(model.parameters())\n",
    "\n",
    "criterion=nn.CrossEntropyLoss()\n",
    "EPOCH=2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop\n",
    "### Optimizer-\n",
    "Adam- Combines advantages of Adaptive Gradient Algorithm and RMSProp\n",
    "\n",
    "### Loss Function-\n",
    "BCEWithLogitsLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_loss_dat=[]\n",
    "epoch_num_correct=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,train_iter):\n",
    "    for epoch in range(1,20):\n",
    "        running_loss=0.0\n",
    "        running_corrects=0\n",
    "        model.train()\n",
    "        epoch_lo=0\n",
    "        for x,y in tqdm.tqdm(train_iter):\n",
    "            optimizer.zero_grad()\n",
    "            #print(x)\n",
    "            preds=model(x)\n",
    "            \n",
    "            #print(f\"y: {y.shape}\")\n",
    "            preds=preds.squeeze(0)\n",
    "        \n",
    "            epoch_lo+=(torch.max(preds,1)[1]==torch.max(y,1)[1]).sum()\n",
    "            \n",
    "            loss=criterion(preds,torch.max(y,1)[1])\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss+=loss.item()*x.size(0)\n",
    "        epoch_loss=running_loss/train_data.shape[0]\n",
    "        epoch_loss_dat.append(epoch_loss)\n",
    "        print(f'Epoch :{epoch}, Training Loss: {epoch_loss}, Num_Correct={epoch_lo}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]\u001b[A/home/ishan/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:50: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "\n",
      "  7%|▋         | 1/15 [00:00<00:06,  2.02it/s]\u001b[A\n",
      " 13%|█▎        | 2/15 [00:00<00:06,  2.11it/s]\u001b[A\n",
      " 20%|██        | 3/15 [00:01<00:05,  2.09it/s]\u001b[A\n",
      " 27%|██▋       | 4/15 [00:01<00:05,  2.08it/s]\u001b[A\n",
      " 33%|███▎      | 5/15 [00:02<00:04,  2.05it/s]\u001b[A\n",
      " 40%|████      | 6/15 [00:02<00:04,  2.12it/s]\u001b[A\n",
      " 47%|████▋     | 7/15 [00:03<00:03,  2.17it/s]\u001b[A\n",
      " 53%|█████▎    | 8/15 [00:03<00:02,  2.40it/s]\u001b[A\n",
      " 60%|██████    | 9/15 [00:03<00:02,  2.57it/s]\u001b[A\n",
      " 67%|██████▋   | 10/15 [00:04<00:02,  2.39it/s]\u001b[A\n",
      " 73%|███████▎  | 11/15 [00:05<00:02,  1.95it/s]\u001b[A\n",
      " 80%|████████  | 12/15 [00:05<00:01,  1.94it/s]\u001b[A\n",
      " 87%|████████▋ | 13/15 [00:06<00:01,  1.99it/s]\u001b[A\n",
      " 93%|█████████▎| 14/15 [00:06<00:00,  2.13it/s]\u001b[A\n",
      "100%|██████████| 15/15 [00:07<00:00,  2.14it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :1, Training Loss: 1.622187690553403, Num_Correct=122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  7%|▋         | 1/15 [00:00<00:06,  2.08it/s]\u001b[A\n",
      " 13%|█▎        | 2/15 [00:01<00:06,  1.97it/s]\u001b[A\n",
      " 20%|██        | 3/15 [00:01<00:05,  2.19it/s]\u001b[A\n",
      " 27%|██▋       | 4/15 [00:01<00:05,  2.12it/s]\u001b[A\n",
      " 33%|███▎      | 5/15 [00:02<00:05,  1.94it/s]\u001b[A\n",
      " 40%|████      | 6/15 [00:02<00:04,  1.99it/s]\u001b[A\n",
      " 47%|████▋     | 7/15 [00:03<00:03,  2.26it/s]\u001b[A\n",
      " 53%|█████▎    | 8/15 [00:03<00:03,  2.24it/s]\u001b[A\n",
      " 60%|██████    | 9/15 [00:04<00:02,  2.38it/s]\u001b[A\n",
      " 67%|██████▋   | 10/15 [00:04<00:02,  2.47it/s]\u001b[A\n",
      " 73%|███████▎  | 11/15 [00:04<00:01,  2.34it/s]\u001b[A\n",
      " 80%|████████  | 12/15 [00:05<00:01,  2.63it/s]\u001b[A\n",
      " 87%|████████▋ | 13/15 [00:05<00:00,  2.82it/s]\u001b[A\n",
      " 93%|█████████▎| 14/15 [00:05<00:00,  2.64it/s]\u001b[A\n",
      "100%|██████████| 15/15 [00:06<00:00,  2.32it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :2, Training Loss: 1.5712441085004907, Num_Correct=141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  7%|▋         | 1/15 [00:00<00:06,  2.31it/s]\u001b[A\n",
      " 13%|█▎        | 2/15 [00:00<00:05,  2.30it/s]\u001b[A\n",
      " 20%|██        | 3/15 [00:01<00:05,  2.32it/s]\u001b[A\n",
      " 27%|██▋       | 4/15 [00:01<00:04,  2.29it/s]\u001b[A\n",
      " 33%|███▎      | 5/15 [00:02<00:04,  2.47it/s]\u001b[A\n",
      " 40%|████      | 6/15 [00:02<00:03,  2.30it/s]\u001b[A\n",
      " 47%|████▋     | 7/15 [00:03<00:03,  2.10it/s]\u001b[A\n",
      " 53%|█████▎    | 8/15 [00:03<00:02,  2.34it/s]\u001b[A\n",
      " 60%|██████    | 9/15 [00:03<00:02,  2.59it/s]\u001b[A\n",
      " 67%|██████▋   | 10/15 [00:04<00:02,  2.48it/s]\u001b[A\n",
      " 73%|███████▎  | 11/15 [00:04<00:01,  2.32it/s]\u001b[A\n",
      " 80%|████████  | 12/15 [00:05<00:01,  2.22it/s]\u001b[A\n",
      " 87%|████████▋ | 13/15 [00:05<00:00,  2.23it/s]\u001b[A\n",
      " 93%|█████████▎| 14/15 [00:06<00:00,  2.31it/s]\u001b[A\n",
      "100%|██████████| 15/15 [00:06<00:00,  2.34it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :3, Training Loss: 1.4937740818894691, Num_Correct=189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  7%|▋         | 1/15 [00:00<00:07,  1.94it/s]\u001b[A\n",
      " 13%|█▎        | 2/15 [00:01<00:07,  1.85it/s]\u001b[A\n",
      " 20%|██        | 3/15 [00:01<00:05,  2.00it/s]\u001b[A\n",
      " 27%|██▋       | 4/15 [00:02<00:05,  2.02it/s]\u001b[A\n",
      " 33%|███▎      | 5/15 [00:02<00:04,  2.17it/s]\u001b[A\n",
      " 40%|████      | 6/15 [00:02<00:04,  2.10it/s]\u001b[A\n",
      " 47%|████▋     | 7/15 [00:03<00:03,  2.24it/s]\u001b[A\n",
      " 53%|█████▎    | 8/15 [00:03<00:03,  2.25it/s]\u001b[A\n",
      " 60%|██████    | 9/15 [00:04<00:02,  2.32it/s]\u001b[A\n",
      " 67%|██████▋   | 10/15 [00:04<00:02,  2.42it/s]\u001b[A\n",
      " 73%|███████▎  | 11/15 [00:04<00:01,  2.28it/s]\u001b[A\n",
      " 80%|████████  | 12/15 [00:05<00:01,  2.55it/s]\u001b[A\n",
      " 87%|████████▋ | 13/15 [00:05<00:00,  2.78it/s]\u001b[A\n",
      " 93%|█████████▎| 14/15 [00:06<00:00,  2.44it/s]\u001b[A\n",
      "100%|██████████| 15/15 [00:06<00:00,  2.28it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :4, Training Loss: 1.4502836768269287, Num_Correct=212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  7%|▋         | 1/15 [00:00<00:05,  2.60it/s]\u001b[A\n",
      " 13%|█▎        | 2/15 [00:00<00:04,  2.61it/s]\u001b[A\n",
      " 20%|██        | 3/15 [00:01<00:04,  2.43it/s]\u001b[A\n",
      " 27%|██▋       | 4/15 [00:01<00:04,  2.49it/s]\u001b[A\n",
      " 33%|███▎      | 5/15 [00:02<00:04,  2.49it/s]\u001b[A\n",
      " 40%|████      | 6/15 [00:02<00:03,  2.38it/s]\u001b[A\n",
      " 47%|████▋     | 7/15 [00:02<00:03,  2.29it/s]\u001b[A\n",
      " 53%|█████▎    | 8/15 [00:03<00:02,  2.50it/s]\u001b[A\n",
      " 60%|██████    | 9/15 [00:03<00:02,  2.44it/s]\u001b[A\n",
      " 67%|██████▋   | 10/15 [00:04<00:02,  2.14it/s]\u001b[A\n",
      " 73%|███████▎  | 11/15 [00:04<00:02,  1.94it/s]\u001b[A\n",
      " 80%|████████  | 12/15 [00:05<00:01,  1.88it/s]\u001b[A\n",
      " 87%|████████▋ | 13/15 [00:05<00:00,  2.23it/s]\u001b[A\n",
      " 93%|█████████▎| 14/15 [00:06<00:00,  2.45it/s]\u001b[A\n",
      "100%|██████████| 15/15 [00:06<00:00,  2.28it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :5, Training Loss: 1.5188141368156256, Num_Correct=175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  7%|▋         | 1/15 [00:00<00:06,  2.09it/s]\u001b[A\n",
      " 13%|█▎        | 2/15 [00:00<00:06,  2.11it/s]\u001b[A\n",
      " 20%|██        | 3/15 [00:01<00:05,  2.11it/s]\u001b[A\n",
      " 27%|██▋       | 4/15 [00:01<00:04,  2.43it/s]\u001b[A\n",
      " 33%|███▎      | 5/15 [00:01<00:03,  2.64it/s]\u001b[A\n",
      " 40%|████      | 6/15 [00:02<00:03,  2.48it/s]\u001b[A\n",
      " 47%|████▋     | 7/15 [00:02<00:03,  2.39it/s]\u001b[A\n",
      " 53%|█████▎    | 8/15 [00:03<00:02,  2.52it/s]\u001b[A\n",
      " 60%|██████    | 9/15 [00:03<00:02,  2.38it/s]\u001b[A\n",
      " 67%|██████▋   | 10/15 [00:04<00:01,  2.55it/s]\u001b[A\n",
      " 73%|███████▎  | 11/15 [00:04<00:01,  2.71it/s]\u001b[A\n",
      " 80%|████████  | 12/15 [00:04<00:01,  2.43it/s]\u001b[A\n",
      " 87%|████████▋ | 13/15 [00:05<00:00,  2.60it/s]\u001b[A\n",
      " 93%|█████████▎| 14/15 [00:05<00:00,  2.68it/s]\u001b[A\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.50it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :6, Training Loss: 1.3909984953055674, Num_Correct=239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  7%|▋         | 1/15 [00:00<00:03,  3.58it/s]\u001b[A\n",
      " 13%|█▎        | 2/15 [00:00<00:04,  2.91it/s]\u001b[A\n",
      " 20%|██        | 3/15 [00:01<00:03,  3.11it/s]\u001b[A\n",
      " 27%|██▋       | 4/15 [00:01<00:03,  3.23it/s]\u001b[A\n",
      " 33%|███▎      | 5/15 [00:01<00:03,  2.82it/s]\u001b[A\n",
      " 40%|████      | 6/15 [00:02<00:03,  2.76it/s]\u001b[A\n",
      " 47%|████▋     | 7/15 [00:02<00:03,  2.48it/s]\u001b[A\n",
      " 53%|█████▎    | 8/15 [00:03<00:02,  2.37it/s]\u001b[A\n",
      " 60%|██████    | 9/15 [00:03<00:02,  2.66it/s]\u001b[A\n",
      " 67%|██████▋   | 10/15 [00:03<00:02,  2.38it/s]\u001b[A\n",
      " 73%|███████▎  | 11/15 [00:04<00:01,  2.54it/s]\u001b[A\n",
      " 80%|████████  | 12/15 [00:04<00:01,  2.46it/s]\u001b[A\n",
      " 87%|████████▋ | 13/15 [00:04<00:00,  2.69it/s]\u001b[A\n",
      " 93%|█████████▎| 14/15 [00:05<00:00,  2.58it/s]\u001b[A\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.54it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :7, Training Loss: 1.3543873768276191, Num_Correct=260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  7%|▋         | 1/15 [00:00<00:06,  2.05it/s]\u001b[A\n",
      " 13%|█▎        | 2/15 [00:00<00:05,  2.17it/s]\u001b[A\n",
      " 20%|██        | 3/15 [00:01<00:05,  2.18it/s]\u001b[A\n",
      " 27%|██▋       | 4/15 [00:01<00:04,  2.42it/s]\u001b[A\n",
      " 33%|███▎      | 5/15 [00:02<00:04,  2.28it/s]\u001b[A\n",
      " 40%|████      | 6/15 [00:02<00:03,  2.54it/s]\u001b[A\n",
      " 47%|████▋     | 7/15 [00:02<00:02,  2.89it/s]\u001b[A\n",
      " 53%|█████▎    | 8/15 [00:03<00:02,  2.62it/s]\u001b[A\n",
      " 60%|██████    | 9/15 [00:03<00:02,  2.81it/s]\u001b[A\n",
      " 67%|██████▋   | 10/15 [00:04<00:02,  2.30it/s]\u001b[A\n",
      " 73%|███████▎  | 11/15 [00:04<00:01,  2.26it/s]\u001b[A\n",
      " 80%|████████  | 12/15 [00:04<00:01,  2.47it/s]\u001b[A\n",
      " 87%|████████▋ | 13/15 [00:05<00:00,  2.34it/s]\u001b[A\n",
      " 93%|█████████▎| 14/15 [00:05<00:00,  2.29it/s]\u001b[A\n",
      "100%|██████████| 15/15 [00:06<00:00,  2.46it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :8, Training Loss: 1.3523948454705657, Num_Correct=263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  7%|▋         | 1/15 [00:00<00:03,  3.91it/s]\u001b[A\n",
      " 13%|█▎        | 2/15 [00:00<00:03,  3.94it/s]\u001b[A\n",
      " 20%|██        | 3/15 [00:01<00:04,  2.99it/s]\u001b[A\n",
      " 27%|██▋       | 4/15 [00:01<00:04,  2.65it/s]\u001b[A\n",
      " 33%|███▎      | 5/15 [00:01<00:04,  2.48it/s]\u001b[A\n",
      " 40%|████      | 6/15 [00:02<00:03,  2.28it/s]\u001b[A\n",
      " 47%|████▋     | 7/15 [00:02<00:03,  2.18it/s]\u001b[A\n",
      " 53%|█████▎    | 8/15 [00:03<00:02,  2.39it/s]\u001b[A\n",
      " 60%|██████    | 9/15 [00:03<00:02,  2.28it/s]\u001b[A\n",
      " 67%|██████▋   | 10/15 [00:04<00:02,  2.38it/s]\u001b[A\n",
      " 73%|███████▎  | 11/15 [00:04<00:02,  1.93it/s]\u001b[A\n",
      " 80%|████████  | 12/15 [00:05<00:01,  2.16it/s]\u001b[A\n",
      " 87%|████████▋ | 13/15 [00:05<00:00,  2.12it/s]\u001b[A\n",
      " 93%|█████████▎| 14/15 [00:06<00:00,  2.31it/s]\u001b[A\n",
      "100%|██████████| 15/15 [00:06<00:00,  2.30it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :9, Training Loss: 1.3254319716709613, Num_Correct=279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  7%|▋         | 1/15 [00:00<00:07,  1.86it/s]\u001b[A\n",
      " 13%|█▎        | 2/15 [00:00<00:06,  2.05it/s]\u001b[A\n",
      " 20%|██        | 3/15 [00:01<00:05,  2.03it/s]\u001b[A\n",
      " 27%|██▋       | 4/15 [00:02<00:05,  1.91it/s]\u001b[A\n",
      " 33%|███▎      | 5/15 [00:02<00:05,  1.91it/s]\u001b[A\n",
      " 40%|████      | 6/15 [00:02<00:04,  2.14it/s]\u001b[A\n",
      " 47%|████▋     | 7/15 [00:03<00:03,  2.05it/s]\u001b[A\n",
      " 53%|█████▎    | 8/15 [00:03<00:03,  2.04it/s]\u001b[A\n",
      " 60%|██████    | 9/15 [00:04<00:02,  2.23it/s]\u001b[A\n",
      " 67%|██████▋   | 10/15 [00:04<00:02,  2.22it/s]\u001b[A\n",
      " 73%|███████▎  | 11/15 [00:05<00:01,  2.18it/s]\u001b[A\n",
      " 80%|████████  | 12/15 [00:05<00:01,  2.45it/s]\u001b[A\n",
      " 87%|████████▋ | 13/15 [00:05<00:00,  2.76it/s]\u001b[A\n",
      " 93%|█████████▎| 14/15 [00:06<00:00,  2.41it/s]\u001b[A\n",
      "100%|██████████| 15/15 [00:06<00:00,  2.26it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :10, Training Loss: 1.2847761568508995, Num_Correct=296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  7%|▋         | 1/15 [00:00<00:06,  2.20it/s]\u001b[A\n",
      " 13%|█▎        | 2/15 [00:00<00:06,  2.12it/s]\u001b[A\n",
      " 20%|██        | 3/15 [00:01<00:05,  2.10it/s]\u001b[A\n",
      " 27%|██▋       | 4/15 [00:01<00:05,  2.13it/s]\u001b[A\n",
      " 33%|███▎      | 5/15 [00:02<00:04,  2.17it/s]\u001b[A\n",
      " 40%|████      | 6/15 [00:02<00:04,  2.23it/s]\u001b[A\n",
      " 47%|████▋     | 7/15 [00:03<00:03,  2.39it/s]\u001b[A\n",
      " 53%|█████▎    | 8/15 [00:03<00:02,  2.50it/s]\u001b[A\n",
      " 60%|██████    | 9/15 [00:03<00:02,  2.59it/s]\u001b[A\n",
      " 67%|██████▋   | 10/15 [00:04<00:02,  2.40it/s]\u001b[A\n",
      " 73%|███████▎  | 11/15 [00:04<00:01,  2.33it/s]\u001b[A\n",
      " 80%|████████  | 12/15 [00:05<00:01,  2.24it/s]\u001b[A\n",
      " 87%|████████▋ | 13/15 [00:05<00:00,  2.21it/s]\u001b[A\n",
      " 93%|█████████▎| 14/15 [00:06<00:00,  2.46it/s]\u001b[A\n",
      "100%|██████████| 15/15 [00:06<00:00,  2.32it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :11, Training Loss: 1.2957679617984603, Num_Correct=290\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  7%|▋         | 1/15 [00:00<00:05,  2.67it/s]\u001b[A\n",
      " 13%|█▎        | 2/15 [00:00<00:05,  2.46it/s]\u001b[A\n",
      " 20%|██        | 3/15 [00:01<00:04,  2.58it/s]\u001b[A\n",
      " 27%|██▋       | 4/15 [00:01<00:04,  2.73it/s]\u001b[A\n",
      " 33%|███▎      | 5/15 [00:02<00:03,  2.50it/s]\u001b[A\n",
      " 40%|████      | 6/15 [00:02<00:03,  2.63it/s]\u001b[A\n",
      " 47%|████▋     | 7/15 [00:02<00:03,  2.37it/s]\u001b[A\n",
      " 53%|█████▎    | 8/15 [00:03<00:02,  2.57it/s]\u001b[A\n",
      " 60%|██████    | 9/15 [00:03<00:02,  2.59it/s]\u001b[A\n",
      " 67%|██████▋   | 10/15 [00:04<00:02,  2.45it/s]\u001b[A\n",
      " 73%|███████▎  | 11/15 [00:04<00:01,  2.36it/s]\u001b[A\n",
      " 80%|████████  | 12/15 [00:04<00:01,  2.22it/s]\u001b[A\n",
      " 87%|████████▋ | 13/15 [00:05<00:00,  2.22it/s]\u001b[A\n",
      " 93%|█████████▎| 14/15 [00:05<00:00,  2.33it/s]\u001b[A\n",
      "100%|██████████| 15/15 [00:06<00:00,  2.47it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :12, Training Loss: 1.2521451865391802, Num_Correct=307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  7%|▋         | 1/15 [00:00<00:06,  2.02it/s]\u001b[A\n",
      " 13%|█▎        | 2/15 [00:01<00:06,  1.89it/s]\u001b[A\n",
      " 20%|██        | 3/15 [00:01<00:05,  2.13it/s]\u001b[A\n",
      " 27%|██▋       | 4/15 [00:01<00:04,  2.34it/s]\u001b[A\n",
      " 33%|███▎      | 5/15 [00:02<00:04,  2.28it/s]\u001b[A\n",
      " 40%|████      | 6/15 [00:02<00:03,  2.30it/s]\u001b[A\n",
      " 47%|████▋     | 7/15 [00:03<00:03,  2.45it/s]\u001b[A\n",
      " 53%|█████▎    | 8/15 [00:03<00:02,  2.41it/s]\u001b[A\n",
      " 60%|██████    | 9/15 [00:03<00:02,  2.33it/s]\u001b[A\n",
      " 67%|██████▋   | 10/15 [00:04<00:02,  2.28it/s]\u001b[A\n",
      " 73%|███████▎  | 11/15 [00:04<00:01,  2.49it/s]\u001b[A\n",
      " 80%|████████  | 12/15 [00:05<00:01,  2.50it/s]\u001b[A\n",
      " 87%|████████▋ | 13/15 [00:05<00:00,  2.39it/s]\u001b[A\n",
      " 93%|█████████▎| 14/15 [00:05<00:00,  2.58it/s]\u001b[A\n",
      "100%|██████████| 15/15 [00:06<00:00,  2.40it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :13, Training Loss: 1.2270938049663196, Num_Correct=323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  7%|▋         | 1/15 [00:00<00:04,  2.82it/s]\u001b[A\n",
      " 13%|█▎        | 2/15 [00:00<00:04,  2.74it/s]\u001b[A\n",
      " 20%|██        | 3/15 [00:01<00:04,  2.58it/s]\u001b[A\n",
      " 27%|██▋       | 4/15 [00:01<00:04,  2.30it/s]\u001b[A\n",
      " 33%|███▎      | 5/15 [00:02<00:04,  2.44it/s]\u001b[A\n",
      " 40%|████      | 6/15 [00:02<00:04,  2.21it/s]\u001b[A\n",
      " 47%|████▋     | 7/15 [00:02<00:03,  2.55it/s]\u001b[A\n",
      " 53%|█████▎    | 8/15 [00:03<00:02,  2.41it/s]\u001b[A\n",
      " 60%|██████    | 9/15 [00:03<00:02,  2.53it/s]\u001b[A\n",
      " 67%|██████▋   | 10/15 [00:04<00:01,  2.73it/s]\u001b[A\n",
      " 73%|███████▎  | 11/15 [00:04<00:01,  2.56it/s]\u001b[A\n",
      " 80%|████████  | 12/15 [00:04<00:01,  2.86it/s]\u001b[A\n",
      " 87%|████████▋ | 13/15 [00:05<00:00,  2.86it/s]\u001b[A\n",
      " 93%|█████████▎| 14/15 [00:05<00:00,  2.59it/s]\u001b[A\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.58it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :14, Training Loss: 1.2238501338071601, Num_Correct=320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  7%|▋         | 1/15 [00:00<00:06,  2.17it/s]\u001b[A\n",
      " 13%|█▎        | 2/15 [00:00<00:05,  2.27it/s]\u001b[A\n",
      " 20%|██        | 3/15 [00:01<00:05,  2.29it/s]\u001b[A\n",
      " 27%|██▋       | 4/15 [00:01<00:04,  2.55it/s]\u001b[A\n",
      " 33%|███▎      | 5/15 [00:02<00:04,  2.34it/s]\u001b[A\n",
      " 40%|████      | 6/15 [00:02<00:03,  2.48it/s]\u001b[A\n",
      " 47%|████▋     | 7/15 [00:02<00:03,  2.56it/s]\u001b[A\n",
      " 53%|█████▎    | 8/15 [00:03<00:02,  2.73it/s]\u001b[A\n",
      " 60%|██████    | 9/15 [00:03<00:02,  2.91it/s]\u001b[A\n",
      " 67%|██████▋   | 10/15 [00:03<00:01,  3.02it/s]\u001b[A\n",
      " 73%|███████▎  | 11/15 [00:04<00:01,  2.91it/s]\u001b[A\n",
      " 80%|████████  | 12/15 [00:04<00:01,  2.71it/s]\u001b[A\n",
      " 87%|████████▋ | 13/15 [00:04<00:00,  2.91it/s]\u001b[A\n",
      " 93%|█████████▎| 14/15 [00:05<00:00,  2.65it/s]\u001b[A\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.72it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :15, Training Loss: 1.2033524704785983, Num_Correct=335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  7%|▋         | 1/15 [00:00<00:06,  2.05it/s]\u001b[A\n",
      " 13%|█▎        | 2/15 [00:00<00:06,  2.03it/s]\u001b[A\n",
      " 20%|██        | 3/15 [00:01<00:05,  2.14it/s]\u001b[A\n",
      " 27%|██▋       | 4/15 [00:01<00:04,  2.44it/s]\u001b[A\n",
      " 33%|███▎      | 5/15 [00:01<00:03,  2.63it/s]\u001b[A\n",
      " 40%|████      | 6/15 [00:02<00:03,  2.75it/s]\u001b[A\n",
      " 47%|████▋     | 7/15 [00:02<00:02,  2.86it/s]\u001b[A\n",
      " 53%|█████▎    | 8/15 [00:03<00:02,  2.51it/s]\u001b[A\n",
      " 60%|██████    | 9/15 [00:03<00:02,  2.36it/s]\u001b[A\n",
      " 67%|██████▋   | 10/15 [00:04<00:02,  2.28it/s]\u001b[A\n",
      " 73%|███████▎  | 11/15 [00:04<00:01,  2.27it/s]\u001b[A\n",
      " 80%|████████  | 12/15 [00:04<00:01,  2.54it/s]\u001b[A\n",
      " 87%|████████▋ | 13/15 [00:05<00:00,  2.32it/s]\u001b[A\n",
      " 93%|█████████▎| 14/15 [00:05<00:00,  2.23it/s]\u001b[A\n",
      "100%|██████████| 15/15 [00:06<00:00,  2.42it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :16, Training Loss: 1.177586301184608, Num_Correct=346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  7%|▋         | 1/15 [00:00<00:04,  3.07it/s]\u001b[A\n",
      " 13%|█▎        | 2/15 [00:00<00:04,  3.18it/s]\u001b[A\n",
      " 20%|██        | 3/15 [00:00<00:03,  3.49it/s]\u001b[A\n",
      " 27%|██▋       | 4/15 [00:01<00:03,  3.60it/s]\u001b[A\n",
      " 33%|███▎      | 5/15 [00:01<00:03,  2.76it/s]\u001b[A\n",
      " 40%|████      | 6/15 [00:02<00:04,  2.15it/s]\u001b[A\n",
      " 47%|████▋     | 7/15 [00:02<00:03,  2.16it/s]\u001b[A\n",
      " 53%|█████▎    | 8/15 [00:03<00:03,  2.13it/s]\u001b[A\n",
      " 60%|██████    | 9/15 [00:03<00:02,  2.18it/s]\u001b[A\n",
      " 67%|██████▋   | 10/15 [00:04<00:02,  2.17it/s]\u001b[A\n",
      " 73%|███████▎  | 11/15 [00:04<00:01,  2.48it/s]\u001b[A\n",
      " 80%|████████  | 12/15 [00:04<00:01,  2.39it/s]\u001b[A\n",
      " 87%|████████▋ | 13/15 [00:05<00:00,  2.69it/s]\u001b[A\n",
      " 93%|█████████▎| 14/15 [00:05<00:00,  2.66it/s]\u001b[A\n",
      "100%|██████████| 15/15 [00:06<00:00,  2.48it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :17, Training Loss: 1.1781905571955706, Num_Correct=343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  7%|▋         | 1/15 [00:00<00:03,  3.76it/s]\u001b[A\n",
      " 13%|█▎        | 2/15 [00:00<00:03,  3.59it/s]\u001b[A\n",
      " 20%|██        | 3/15 [00:00<00:03,  3.47it/s]\u001b[A\n",
      " 27%|██▋       | 4/15 [00:01<00:03,  2.93it/s]\u001b[A\n",
      " 33%|███▎      | 5/15 [00:01<00:04,  2.47it/s]\u001b[A\n",
      " 40%|████      | 6/15 [00:02<00:03,  2.40it/s]\u001b[A\n",
      " 47%|████▋     | 7/15 [00:02<00:03,  2.28it/s]\u001b[A\n",
      " 53%|█████▎    | 8/15 [00:03<00:02,  2.49it/s]\u001b[A\n",
      " 60%|██████    | 9/15 [00:03<00:02,  2.76it/s]\u001b[A\n",
      " 67%|██████▋   | 10/15 [00:03<00:01,  2.65it/s]\u001b[A\n",
      " 73%|███████▎  | 11/15 [00:04<00:01,  2.79it/s]\u001b[A\n",
      " 80%|████████  | 12/15 [00:04<00:01,  2.53it/s]\u001b[A\n",
      " 87%|████████▋ | 13/15 [00:05<00:00,  2.40it/s]\u001b[A\n",
      " 93%|█████████▎| 14/15 [00:05<00:00,  2.30it/s]\u001b[A\n",
      "100%|██████████| 15/15 [00:06<00:00,  2.46it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :18, Training Loss: 1.1542918644294173, Num_Correct=352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  7%|▋         | 1/15 [00:00<00:07,  1.96it/s]\u001b[A\n",
      " 13%|█▎        | 2/15 [00:00<00:06,  2.00it/s]\u001b[A\n",
      " 20%|██        | 3/15 [00:01<00:05,  2.03it/s]\u001b[A\n",
      " 27%|██▋       | 4/15 [00:02<00:05,  1.91it/s]\u001b[A\n",
      " 33%|███▎      | 5/15 [00:02<00:05,  1.91it/s]\u001b[A\n",
      " 40%|████      | 6/15 [00:03<00:04,  2.03it/s]\u001b[A\n",
      " 47%|████▋     | 7/15 [00:03<00:04,  1.95it/s]\u001b[A\n",
      " 53%|█████▎    | 8/15 [00:04<00:03,  1.79it/s]\u001b[A\n",
      " 60%|██████    | 9/15 [00:04<00:03,  1.80it/s]\u001b[A\n",
      " 67%|██████▋   | 10/15 [00:05<00:02,  1.70it/s]\u001b[A\n",
      " 73%|███████▎  | 11/15 [00:05<00:02,  1.81it/s]\u001b[A\n",
      " 80%|████████  | 12/15 [00:06<00:01,  1.90it/s]\u001b[A\n",
      " 87%|████████▋ | 13/15 [00:07<00:01,  1.75it/s]\u001b[A\n",
      " 93%|█████████▎| 14/15 [00:07<00:00,  1.63it/s]\u001b[A\n",
      "100%|██████████| 15/15 [00:08<00:00,  1.82it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :19, Training Loss: 1.161202031008537, Num_Correct=353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train(model,train_dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f4b73dafda0>]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "a=np.arange(19)\n",
    "b=np.ones(19)*473\n",
    "#figs,axs=plt.subplots(1,1,figsize=(10,5))\n",
    "\n",
    "plt.title('Loss vs Epoch')\n",
    "plt.plot(a,epoch_loss_dat,color='g')\n",
    "\n",
    "#plt.title('Number of Correct vs Epoch')\n",
    "#axs[1].plot(a,b,epoch_num_correct,color='teal')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model,valid_iter,val_data_len):\n",
    "    running_loss=0.0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    epoch_lo=0\n",
    "    for x,y in tqdm.tqdm(valid_iter):\n",
    "        \n",
    "        preds=model(x)\n",
    "        preds=preds.squeeze(0)\n",
    "\n",
    "        loss=criterion(preds,torch.max(y,1)[1])\n",
    "        epoch_lo+=(torch.max(preds,1)[1]==torch.max(y,1)[1]).sum()\n",
    "        #print(epoch_lo)\n",
    "        running_loss+=loss.item()*x.shape[0]\n",
    "    \n",
    "    total_loss=running_loss/val_data_len\n",
    "    print(f'Validation Loss: {total_loss}, Num_Correct={epoch_lo}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data import TabularDataset\n",
    "\n",
    "validation_flair_fields=[('Unnamed:0',None),('idx',None),('Title',TEXT),\n",
    "         ('Score',None),('ID',None),('Image',None),('Num_Comments',None),('Created',None),('Body',None),\n",
    "         ('Label1Coronovirus',LABEL),('Label2Politics',LABEL),('Label3Non-Political',LABEL),\n",
    "         ('Label4Objects',LABEL),('Label5AskIndia',LABEL)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data_csv=TabularDataset(path='../dataset/Val_data',\n",
    "                    format='csv',\n",
    "                    skip_header=True,\n",
    "                    fields=validation_flair_fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data import Iterator,BucketIterator\n",
    "\n",
    "val_iterator=BucketIterator(val_data_csv,\n",
    "                             batch_size=32,\n",
    "                             device=torch.device('cpu'),\n",
    "                             sort_key=lambda x:len(x.Title),\n",
    "                             sort_within_batch=True,\n",
    "                             repeat=False\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data=BatchWrapper(val_iterator,'Title',labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A/home/ishan/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:50: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "\n",
      " 10%|█         | 2/20 [00:00<00:01, 15.78it/s]\u001b[A\n",
      " 25%|██▌       | 5/20 [00:00<00:00, 17.35it/s]\u001b[A\n",
      " 40%|████      | 8/20 [00:00<00:00, 19.70it/s]\u001b[A\n",
      " 60%|██████    | 12/20 [00:00<00:00, 22.19it/s]\u001b[A\n",
      " 75%|███████▌  | 15/20 [00:00<00:00, 22.75it/s]\u001b[A\n",
      "100%|██████████| 20/20 [00:00<00:00, 21.33it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 1.5242602098045532, Num_Correct=225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate(model,val_data,len(val_data_csv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Stop Words removing was good"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
